## Sandboxes {#sec-sandboxes}

[k8s Sandbox](https://k8s-sandbox.aisi.org.uk/) &mdash; <small><a href="https://github.com/UKGovernmentBEIS/inspect_k8s_sandbox" style="text-decoration:none">UK AISI</a></small>
:   Python package that provides a Kubernetes sandbox environment for Inspect.

[EC2 Sandbox](https://github.com/UKGovernmentBEIS/inspect_ec2_sandbox) &mdash; <small><a href="https://github.com/UKGovernmentBEIS/inspect_ec2_sandbox" style="text-decoration:none">UK AISI</a></small>
:   Python package that provides a EC2 virtual machine sandbox environment for Inspect.

[Modal Sandbox](https://github.com/meridianlabs-ai/inspect_sandboxes/tree/main/src/inspect_sandboxes/modal) &mdash; <small><a href="https://github.com/meridianlabs-ai/inspect_sandboxes" style="text-decoration:none">Meridian</a></small>
:   Serverless container sandbox for Inspect using Modal's cloud infrastructure.

[Proxmox Sandbox](https://github.com/UKGovernmentBEIS/inspect_proxmox_sandbox) &mdash; <small><a href="https://github.com/UKGovernmentBEIS/inspect_proxmox_sandbox" style="text-decoration:none">UK AISI</a></small>
:   Use virtual machines, running within a Proxmox instance, as Inspect sandboxes.

[Inspect Policy Sandbox](https://github.com/Dedulus/inspect-policy-sandbox) &mdash; <small><a href="https://github.com/Dedulus" style="text-decoration:none">Arnab Mitra</a></small>
:   Sandbox wrapper that allows fine grained control over command execution and file I/O.


## Analysis {#sec-analysis}

[Inspect Scout](https://meridianlabs-ai.github.io/inspect_scout/) &mdash; <small><a href="https://github.com/meridianlabs-ai/inspect_scout" style="text-decoration:none">Meridian</a></small>
:   Transcript analysis for Inspect evaluations.

[Inspect Viz](https://meridianlabs-ai.github.io/inspect_viz/) &mdash; <small><a href="https://github.com/meridianlabs-ai/inspect_viz" style="text-decoration:none">Meridian</a></small>
:   Interactive data visualization for Inspect evaluations.

[Docent](https://docs.transluce.org/) &mdash; <small><a href="https://transluce.org/introducing-docent" style="text-decoration:none">Transluce</a></small>
:   Tools to summarize, cluster, and search over agent transcripts.

[Lunette](https://docs.lunette.dev) &mdash; <small><a href="https://fulcrumresearch.ai" style="text-decoration:none">Fulcrum Research</a></small>
:   Platform for understanding and improving agents.

[Inspect WandB](https://github.com/DanielPolatajko/inspect_wandb) &mdash; <small><a href="https://www.arcadiaimpact.org/" style="text-decoration:none">Arcadia</a></small>
:   Integration with Weights and Biases platform.


## Frameworks {#sec-frameworks}

[Inspect SWE](https://meridianlabs-ai.github.io/inspect_swe/) &mdash; <small><a href="https://github.com/meridianlabs-ai/inspect_swe" style="text-decoration:none">Meridian</a></small>
:   Software engineering agents (Claude Code and Codex CLI) for Inspect.

[Inspect Cyber](https://ukgovernmentbeis.github.io/inspect_cyber/) &mdash; <small><a href="https://github.com/UKGovernmentBEIS/inspect_cyber" style="text-decoration:none">UK AISI</a></small>
:   Python package that streamlines the process of creating agentic cyber evaluations in Inspect.

[Petri](https://safety-research.github.io/petri/) &mdash; <small><a href="https://www.anthropic.com/research/petri-open-source-auditing" style="text-decoration:none">Anthropic</a></small>
:   Framework testing alignment hypotheses end‑to‑end, including automatic scenario generation.

[Control Arena](https://github.com/UKGovernmentBEIS/control-arena) &mdash; <small><a href="https://github.com/UKGovernmentBEIS/control-arena" style="text-decoration:none">UK AISI</a></small>
:   Framework for running experiments on AI Control and Monitoring.


## Tooling {#sec-tooling}

[Inspect Flow](https://meridianlabs-ai.github.io/inspect_flow/) &mdash; <small><a href="https://github.com/meridianlabs-ai/inspect_flow" style="text-decoration:none">Meridian</a></small>
:   Workflow orchestration for reprocibly running evals at scale.

[Evaljobs](https://github.com/dvsrepo/evaljobs) &mdash; <small><a href="https://github.com/dvsrepo/evaljobs" style="text-decoration:none">Hugging Face</a></small>
:   Run evals on Hugging Face GPUs and share results and code on the Hugging Face Hub.

[Inspect VS Code](https://marketplace.visualstudio.com/items?itemName=ukaisi.inspect-ai) &mdash; <small><a href="https://github.com/meridianlabs-ai/inspect-vscode" style="text-decoration:none">Meridian</a></small>
:   VS Code extension that assists with developing and debugging Inspect evaluations.


## Evals {#sec-evals}

[Inspect Evals](https://ukgovernmentbeis.github.io/inspect_evals/) &mdash; <small><a href="https://github.com/UKGovernmentBEIS/inspect_evals" style="text-decoration:none">UK AISI</a></small>
:   Over 1000 LLM evaluations covering safety, coding, reasoning, knowledge, and agent capabilities.

[OpenBench](https://github.com/groq/openbench) &mdash; <small><a href="https://github.com/groq" style="text-decoration:none">Groq</a></small>
:   Standardized, reproducible benchmarking for LLMs across 30+ evals.

[Inspect Harbor](https://github.com/meridianlabs-ai/inspect_harbor) &mdash; <small><a href="https://github.com/meridianlabs-ai/inspect_harbor" style="text-decoration:none">Meridian</a></small>
:   Evals from Harbor framework including terminal-bench, replicationbench, and compilebench.

